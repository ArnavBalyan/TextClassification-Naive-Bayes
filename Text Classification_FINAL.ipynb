{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various models required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os,sys\n",
    "from sklearn import model_selection\n",
    "import re,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This are stop_words in common taken from intenet.\n",
    "stop_word=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\n",
    "\"by\",\"could\",\"did\",\"do\",\"does\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n",
    "\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\n",
    "\"more\",\"most\",\"my\",\"myself\",\"nor\",\"of\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"she\",\n",
    "\"she'd\",\"she'll\",\"she's\",\"should\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\n",
    "\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"we\",\"we'd\",\n",
    "\"we'll\",\"we're\",\"we've\",\"were\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\n",
    "\"would\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is a list further made in form of tuple , where first element is name of document and second is the text in documents.\n",
    "#Y is the category\n",
    "X  =[] \n",
    "Y = []\n",
    "for category in os.listdir(\"C:/Users/Arnav/mini_newsgroups/\"):\n",
    "    for document in os.listdir(\"C:/Users/Arnav/mini_newsgroups/\"+category):\n",
    "        with open(\"C:/Users/Arnav/mini_newsgroups/\"+category+'/'+document, \"r\") as f:\n",
    "            X.append((document,f.read()))\n",
    "            Y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "('51121', 'Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51121 soc.motss:139944 rec.scouting:5318\\nNewsgroups: alt.atheism,soc.motss,rec.scouting\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!wupost!uunet!newsgate.watson.ibm.com!yktnews.watson.ibm.com!watson!Watson.Ibm.Com!strom\\nFrom: strom@Watson.Ibm.Com (Rob Strom)\\nSubject: Re: [soc.motss, et al.] \"Princeton axes matching funds for Boy Scouts\"\\nSender: @watson.ibm.com\\nMessage-ID: <1993Apr05.180116.43346@watson.ibm.com>\\nDate: Mon, 05 Apr 93 18:01:16 GMT\\nDistribution: usa\\nReferences: <C47EFs.3q47@austin.ibm.com> <1993Mar22.033150.17345@cbnewsl.cb.att.com> <N4HY.93Apr5120934@harder.ccr-p.ida.org>\\nOrganization: IBM Research\\nLines: 15\\n\\nIn article <N4HY.93Apr5120934@harder.ccr-p.ida.org>, n4hy@harder.ccr-p.ida.org (Bob McGwier) writes:\\n\\n|> [1] HOWEVER, I hate economic terrorism and political correctness\\n|> worse than I hate this policy.  \\n\\n\\n|> [2] A more effective approach is to stop donating\\n|> to ANY organizating that directly or indirectly supports gay rights issues\\n|> until they end the boycott on funding of scouts.  \\n\\nCan somebody reconcile the apparent contradiction between [1] and [2]?\\n\\n-- \\nRob Strom, strom@watson.ibm.com, (914) 784-7641\\nIBM Research, 30 Saw Mill River Road, P.O. Box 704, Yorktown Heights, NY  10598\\n')\n"
     ]
    }
   ],
   "source": [
    "#DataType of X and Y in detail\n",
    "print(type(X))\n",
    "print(type(X[0]))\n",
    "print(type(X[0][0]))\n",
    "print(type(X[0][1]))\n",
    "print(type(Y))\n",
    "#We can see it is a tuple with first element as name of document and second text of document.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data in training and testing\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#split has done in nearly 3:1 ratio\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hey', 'whatsupp', 'I', 'am', 'fine', 'Whatchu', 'you', 'doing', 'there', '']\n"
     ]
    }
   ],
   "source": [
    "#Demonstrating re.split\n",
    "sample_text=\"Hey! whatsupp. I am fine. Whatchu you doing there?\"\n",
    "print(re.split(r'\\W+',sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Dictionary of words with their corresponding frequency\n",
    "dic={}\n",
    "for i in range(len(x_train)):\n",
    "    #Took [1] because [0] is name of doc and [1] is text in doc\n",
    "    word=x_train[i][1].lower()\n",
    "    #splitting the text into words\n",
    "    stripped=re.split(r'\\W+',word)\n",
    "    #Iterating over each word\n",
    "    for s in stripped:\n",
    "        #we will not include stop_words, alpha-numerics, punctuations or irrelevant word of length less than 2 in our dictionary\n",
    "        if not(s.isalpha()) or s in stop_word or len(s)<=2:\n",
    "            continue\n",
    "        if s in dic:\n",
    "            dic[s]+=1\n",
    "        else:\n",
    "            dic[s]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the dictionary on basis of frequency of words in descending order\n",
    "sorted_dic = sorted(dic.items(), key=operator.itemgetter(1),reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZbklEQVR4nO3de2xc53nn8e8zHJKiqLslW9TFkWSzqWW0sR2vrMSbgBsn8qVBZKDxQkbRqFkFAroGNtku0NpbYI0kDZAU3SbIok0j1Noq2Ta2N4nXWsOto8qezTpZy/IttmVZFm3JEitZtEPdqAvJ4Tz7x7wjjSkeDmUP+b5j/j7AYM555j3nPKMZ6sdzmaG5OyIiIqPJxW5ARETSpZAQEZFMCgkREcmkkBARkUwKCRERyaSQEBGRTOMKCTPbb2YvmdkLZvZMqM0zs21mtjfczw11M7Pvmlm3mb1oZtdVrWd9GL/XzNZPzFMSEZF6uZg9iX/j7te4+/Vh/m5gu7t3AtvDPMCtQGe4bQS+B+VQAe4FbgBWAfdWgkVERNL0fg43rQW2hOktwO1V9R942VPAHDPrAG4Gtrl7n7sfBbYBt7yP7YuIyATLj3OcAz8zMwe+7+6bgMvc/TCAux82s0vD2MXAwaple0Itq/4uZraR8h4IubZZH122eCH5xM+clEolcrnEm0R91pv6rJ9G6BEap8/XXnvtHXdfUI91jTckbnT3QyEItpnZq2OMtVFqPkb93YVyAG0CaO3o9J/vfIHFc9rG2WYchUKBrq6u2G3UpD7rS33WTyP0CI3Tp5m9Wa91jSsS3f1QuO8FHqJ8TuFIOIxEuO8Nw3uApVWLLwEOjVEXEZFE1QwJM2s3s5mVaWAN8DKwFahcobQeeDhMbwW+EK5yWg0cD4elHgPWmNnccMJ6TaiJiEiixnO46TLgITOrjP8Hd/8nM9sJPGhmG4ADwB1h/KPAbUA3cBr4IoC795nZ14GdYdzX3L2v1sb1LbUiIvHUDAl3fwP4yCj1XwM3jVJ34K6MdW0GNl98myIiEkP6p+lFRCQahYSIiGRSSIiISKbkQ0LnrUVE4kk+JEREJB6FhIiIZFJIiIhIJoWEiIhkUkiIiEgmhYSIiGRSSIiISCaFhIiIZFJIiIhIpuRDQp+4FhGJJ/mQEBGReBQSIiKSSSEhIiKZFBIiIpIp+ZBwdOZaRCSW5ENCRETiUUiIiEgmhYSIiGRSSIiISKbkQ0KfuBYRiSf5kBARkXgUEiIikkkhISIimRQSIiKSKfmQ0HlrEZF4kg8JERGJRyEhIiKZFBIiIpJJISEiIpmSDwnXR65FRKJJPiRERCSecYeEmTWZ2fNm9kiYX25mO8xsr5k9YGYtod4a5rvD48uq1nFPqO8xs5vr/WRERKS+LmZP4svA7qr5bwHfdvdO4CiwIdQ3AEfd/Urg22EcZrYSWAdcDdwC/LWZNb2/9kVEZCKNKyTMbAnwO8DfhnkDPgX8OAzZAtwepteGecLjN4Xxa4H73X3A3fcB3cCqejwJERGZGPlxjvsO8MfAzDB/CXDM3YthvgdYHKYXAwcB3L1oZsfD+MXAU1XrrF7mHDPbCGwEaFl4JTt2PM2BGWmfOunv76dQKMRuoyb1WV/qs34aoUdonD7rqWZImNlngV53f9bMuirlUYZ6jcfGWuZ8wX0TsAmgtaPTV92wiisWzKjVZlSFQoGurq7YbdSkPutLfdZPI/QIjdNnPY1nT+JG4HNmdhswDZhFec9ijpnlw97EEuBQGN8DLAV6zCwPzAb6quoV1cuIiEiCah7Hcfd73H2Juy+jfOL5cXf/PeAJ4PNh2Hrg4TC9NcwTHn/cyx922AqsC1c/LQc6gafr9kxERKTuxntOYjR/AtxvZn8GPA/cF+r3AT80s27KexDrANx9l5k9CLwCFIG73H34fWxfREQm2EWFhLsXgEKYfoNRrk5y97PAHRnLfwP4xsVt82JGi4hIPaV92ZCIiESlkBARkUwKCRERyaSQEBGRTA0QEjpzLSISSwOEhIiIxKKQEBGRTAoJERHJpJAQEZFMyYeEPnEtIhJP8iEhIiLxKCRERCSTQkJERDIlHxI6JSEiEk/yISEiIvEoJEREJJNCQkREMikkREQkU/IhoQ/TiYjEk3xIiIhIPAoJERHJpJAQEZFMCgkREcmUfEi4PnMtIhJN8iEhIiLxKCRERCSTQkJERDIpJEREJFPyIaFPXIuIxJN8SIiISDwKCRERyaSQEBGRTAoJERHJlHxI6MS1iEg8NUPCzKaZ2dNm9isz22VmXw315Wa2w8z2mtkDZtYS6q1hvjs8vqxqXfeE+h4zu3minpSIiNTHePYkBoBPuftHgGuAW8xsNfAt4Nvu3gkcBTaE8RuAo+5+JfDtMA4zWwmsA64GbgH+2sya6vlkRESkvmqGhJf1h9nmcHPgU8CPQ30LcHuYXhvmCY/fZGYW6ve7+4C77wO6gVV1eRYiIjIh8uMZFH7jfxa4Evgr4HXgmLsXw5AeYHGYXgwcBHD3opkdBy4J9aeqVlu9TPW2NgIbAVoWXskzz+ykd1baOxz9/f0UCoXYbdSkPutLfdZPI/QIjdNnPY0rJNx9GLjGzOYADwFXjTYs3FvGY1n1kdvaBGwCaO3o9I9efz1XL5o9njajKRQKdHV1xW6jJvVZX+qzfhqhR2icPuvpoq5ucvdjQAFYDcwxs0rILAEOhekeYClAeHw20FddH2UZERFJ0HiubloQ9iAwszbg08Bu4Ang82HYeuDhML01zBMef9zdPdTXhauflgOdwNP1eiIiIlJ/4znc1AFsCeclcsCD7v6Imb0C3G9mfwY8D9wXxt8H/NDMuinvQawDcPddZvYg8ApQBO4Kh7FERCRRNUPC3V8Erh2l/gajXJ3k7meBOzLW9Q3gGxffpoiIxKBPXIuISKbkQ0JEROJRSIiISCaFhIiIZFJIiIhIJoWEiIhkUkiIiEgmhYSIiGRSSIiISCaFhIiIZEo+JIZL+si1iEgsyYfE2SF9B6CISCzJh4R2JERE4kk+JPzCP14nIiKTJP2QUEaIiESTfEiUlBIiItE0QEjE7kBEZOpqgJBQSoiIxJJ8SLhCQkQkmuRDolSK3YGIyNSVfkhoT0JEJJoGCInYHYiITF3Jh4TOSYiIxJN8SGhPQkQkngYICaWEiEgsyYeEIkJEJJ70Q0J7EiIi0SQfEjrcJCIST/ohoQ/TiYhEk35IaE9CRCSa5ENCGSEiEk/yIaE9CRGReBogJGJ3ICIydTVASCglRERiST4k9DkJEZF4aoaEmS01syfMbLeZ7TKzL4f6PDPbZmZ7w/3cUDcz+66ZdZvZi2Z2XdW61ofxe81s/Xga1OEmEZF4xrMnUQT+k7tfBawG7jKzlcDdwHZ37wS2h3mAW4HOcNsIfA/KoQLcC9wArALurQTLWHS4SUQknpoh4e6H3f25MH0S2A0sBtYCW8KwLcDtYXot8AMvewqYY2YdwM3ANnfvc/ejwDbgltrbv8hnJCIidZO/mMFmtgy4FtgBXObuh6EcJGZ2aRi2GDhYtVhPqGXVR25jI+U9EFoWXsne7m4KxTcvps1J19/fT6FQiN1GTeqzvtRn/TRCj9A4fdbTuEPCzGYAPwG+4u4nzCxz6Cg1H6P+7oL7JmATQGtHp69YcQVdn1wx3jajKBQKdHV1xW6jJvVZX+qzfhqhR2icPutpXFc3mVkz5YD4e3f/aSgfCYeRCPe9od4DLK1afAlwaIz6mHROQkQknvFc3WTAfcBud//Lqoe2ApUrlNYDD1fVvxCucloNHA+HpR4D1pjZ3HDCek2ojUlXN4mIxDOew003Ar8PvGRmL4Tafwa+CTxoZhuAA8Ad4bFHgduAbuA08EUAd+8zs68DO8O4r7l7X62Na09CRCSemiHh7k8y+vkEgJtGGe/AXRnr2gxsvpgG9WE6EZF4kv/EtQ43iYjE0wAhoZQQEYmlAUIidgciIlNX8iGhcxIiIvEkHxI63CQiEk8DhETsDkREpq6kQ8LQF/yJiMSUdEiAzkmIiMSUfEjonISISDwNEBKxOxARmbqSDglDexIiIjElHRKYTlyLiMSUdEgYMFAcjt2GiMiUlX5IDJVityEiMmWlHRIGg8MKCRGRWJIOCYAhhYSISDRJh4QBQ8M6cy0iEkvaIWHakxARiSntkAAGiwoJEZFYkg4JgKI+ci0iEk3SIWFmOtwkIhJR2iGBDjeJiMSUdEiADjeJiMSUdEgYMKyQEBGJJumQwBQSIiIxJR0S2pMQEYkr6ZAAKJZ04lpEJJakQ0J7EiIicSUdEpiubhIRiSnpkDBgWF/wJyISTdIhAdqTEBGJKemQ0DkJEZG4kg4JgGFXSIiIxJJ0SFj4MF1JexMiIlHUDAkz22xmvWb2clVtnpltM7O94X5uqJuZfdfMus3sRTO7rmqZ9WH8XjNbP57mLNzr71yLiMQxnj2JvwNuGVG7G9ju7p3A9jAPcCvQGW4bge9BOVSAe4EbgFXAvZVgGYuFlBgYUkiIiMRQMyTc/edA34jyWmBLmN4C3F5V/4GXPQXMMbMO4GZgm7v3uftRYBsXBs8FKnsSA8PDNZ+IiIjUX/49LneZux8GcPfDZnZpqC8GDlaN6wm1rPoFzGwj5b0QZl+6mBbg50/+kvlt6Z4+6e/vp1AoxG6jJvVZX+qzfhqhR2icPuvpvYZEFhul5mPULyy6bwI2ASxZ8RsOcO31q7hiwYx69Vh3hUKBrq6u2G3UpD7rS33WTyP0CI3TZz2911/Pj4TDSIT73lDvAZZWjVsCHBqjPi7663QiInG815DYClSuUFoPPFxV/0K4ymk1cDwclnoMWGNmc8MJ6zWhNqbKiWuFhIhIHDUPN5nZj4AuYL6Z9VC+SumbwINmtgE4ANwRhj8K3AZ0A6eBLwK4e5+ZfR3YGcZ9zd1Hngy/cNvhKNWAQkJEJIqaIeHud2Y8dNMoYx24K2M9m4HNF9Oc9iREROJK95Ihqi6BLeoSWBGRGNIOiZASpwcVEiIiMSQdEk0hJE6eLcZtRERkiko6JCqHm04PKiRERGJIOyRCSpzR4SYRkSjSDgkgnzNOKSRERKJIOiQALps1jcPHz8RuQ0RkSko+JBbPbeOt42djtyEiMiUlHxLzprdw9PRg7DZERKak5ENibnsLfaeGYrchIjIlJR8S89qbead/gPI3foiIyGRKPiTyuXKLh3VeQkRk0iUfEh9eOBOA42d0yElEZLIlHxKzpjUD+moOEZEYkg+JOdPLIfHr/oHInYiITD3Jh8Sy+e0AvPHOqcidiIhMPcmHxIzWPAtnTeP1t/tjtyIiMuUkHxIAV146g+5ehYSIyGRriJC4qmMme946SXFYf8ZURGQyNURIrFw0i4FiiX06LyEiMqkaIiSu6pgFwCuHT0TuRERkammIkLhiwQxa8jme3tcXuxURkSmlIUKiuSnHmpWX8ehLhymV9B1OIiKTpSFCAuAzKy/j6Okh/t8bv47diojIlNFQIdHe0sTmJ/fpG2FFRCZJw4TE9JY8X/50J9tf7aWw5+3Y7YiITAkNExIAf/Dx5Vw+bzp//tgenZsQEZkEDRUSLfkcf/SZ32D34RP8t8e7Y7cjIvKB11AhAbD2mkX8zm918J3tr/Hk3ndityMi8oHWcCFhZnzzd3+LFfPb2bBlJ1/937s4emowdlsiIh9IDRcSADOnNfM/vnQDn/3tRfzdL/fT9RcFHth5gP4B/WEiEZF6asiQAOiY3cZ//bcf4dH/8AmWzW/nT37yEh/9+ja+tOUZNj+5j71HTurktojI+5SP3cD7dVXHLB76w4/zi9ff4We7jvB/Xnubf959BICZrXn+1fJ53HL1Qm5YMY/L503HzCJ3LCLSOBo+JAByOeMTnQv4ROcCAA72nebJ7nd4secYhT1v8/irvQDMn9HK1YtmsWRuG1csmMHC2dNYNKeNRXOmcUl7K005BYiISLUPREiMtHTedO5cdTl3rrqcUsl5rfckO/cf5bk3j7LnrZM8++bRC85fNOWMudNbmD+jhXntLcyclmfu9BZmtzUzt72FtuYmZrTmmTktz/SWPHOmN9PemmdOWzMDw06p5OQUMiLyAfOBDIlquZzxmwtn8ZsLZ/H7qz8EgLvTd2qQIycG+JdjZ3jr+BneOnGWd04OcvT0IO/0D9B3apBn3zzGybNDDBTH8ceOtj3KzNY8zfkcLU052lqaaG9toqUpR0s+x6xpzbTky9PtLXnaWprI54x8U46WJmPmtGbyTUZzLke+yWjNNzG9pYlczmgyoyl3/jatOUdrPofZ+cdyOSNn0GTldU5vaSJnoZYzHWYTkffkAx8SozEzLpnRyiUzWlm5aNaYY92d04PDnB0a5sTZIqcGivQPFDl+Zoj+s+X73a/tpWPJhzg5UGRouMRQ0ekfLHJmcJjBYomB4jAH+k6H6RL9A0UGisMUh53iJJ5czxk0bXv0XLi0NudobsqRM0KgGHZumnfNm0FbS56mqnkzw7hw3Pn6+VpLvrwt4/zjVB6H8nKUxx4+PMBjfS+F2vnHcmHdUA6+tuYmOPd4mOD8MuVpO/94ZWxVYFZvt3rZ0OH5epjIh5AG2NMzRO/Og+dXTvV2bMT8iPsR66fWciP7GfF4dXXkmF29RYZeOYIBzfkczU3v3qgxYn5kT4yYt4sdz8jKBY91Hxtm1oGjtbdVY921nssFnVzk8gdPlnj1rROjjp/WnCP3AfxlbEqGxMUwM9pb87S35rlkRuuoYwrFN+nq+vB7Wr+7M1AscWqgSLHkDA2XGC6dD6aSO8MlKJZKlML9mcFhhkqOuzNcKt9K7pQchsM6zg6VyrVSqLuzb/9+li69nJKXt3tqsFhetgQld5xw75xbX3nez/XkDk55Gef8NivLe1iuMl1Z15mhYYZLfm55d8Ktstz5+sDgMLuOHYHKuKq+KuOLw87gcOldy0fx8ouRNnyRnnsmdge1PfXL2B2Mzy/+b+wOJpWl/I2qZnYS2BO7j3GYDzTCx7/VZ32pz/pphB6hcfr8sLvPrMeKUt+T2OPu18duohYze0Z91o/6rK9G6LMReoTG6rNe62rYD9OJiMjEU0iIiEim1ENiU+wGxkl91pf6rK9G6LMReoQp2GfSJ65FRCSu1PckREQkIoWEiIhkSjYkzOwWM9tjZt1mdneE7W82s14ze7mqNs/MtpnZ3nA/N9TNzL4ben3RzK6rWmZ9GL/XzNbXucelZvaEme02s11m9uVE+5xmZk+b2a9Cn18N9eVmtiNs8wEzawn11jDfHR5fVrWue0J9j5ndXM8+q7bRZGbPm9kjqfZpZvvN7CUze6FyuWNqr3tY/xwz+7GZvRrepx9LrU8z+3D4d6zcTpjZVxLs8z+Gn5+XzexH4edq4t+bHj5Rm9INaAJeB1YALcCvgJWT3MMngeuAl6tqfw7cHabvBr4Vpm8D/pHytwasBnaE+jzgjXA/N0zPrWOPHcB1YXom8BqwMsE+DZgRppuBHWH7DwLrQv1vgD8M0/8e+JswvQ54IEyvDO+FVmB5eI80TcBr/0fAPwCPhPnk+gT2A/NH1JJ63cM2tgBfCtMtwJwU+6zqtwl4C/hQSn0Ci4F9QFvVe/IPJuO9Wfd/5Dr9g3wMeKxq/h7gngh9LOPdIbEH6AjTHZQ/7AfwfeDOkeOAO4HvV9XfNW4C+n0Y+EzKfQLTgeeAGyh/cjU/8jUHHgM+FqbzYZyNfB9Uj6tjf0uA7cCngEfCdlPscz8XhkRSrzswi/J/bJZynyN6WwP8IrU+KYfEQcoBlA/vzZsn472Z6uGmyj9IRU+oxXaZux8GCPeXhnpWv5P2PMLu5LWUf0tPrs9wCOcFoBfYRvk3mGPuXvnO9uptnusnPH4cuGQy+gS+A/wxUPnq30sS7dOBn5nZs2a2MdRSe91XAG8D/z0cvvtbM2tPsM9q64Afhelk+nT3fwH+AjgAHKb8XnuWSXhvphoSo32VYsrX6mb1OynPw8xmAD8BvuLuJ8YamtHPhPfp7sPufg3l39RXAVeNsc0ofZrZZ4Fed3+2ujzGNmO+7je6+3XArcBdZvbJMcbG6jNP+ZDt99z9WuAU5cM2WWL/HLUAnwP+Z62hGf1MWJ/hfMhayoeIFgHtlF/7rO3VrcdUQ6IHWFo1vwQ4FKmXakfMrAMg3PeGela/E/48zKyZckD8vbv/NNU+K9z9GFCgfCx3jplVvj+sepvn+gmPzwb6JqHPG4HPmdl+4H7Kh5y+k2CfuPuhcN8LPEQ5eFN73XuAHnffEeZ/TDk0Uuuz4lbgOXc/EuZT6vPTwD53f9vdh4CfAh9nEt6bqYbETqAznLlvobwLuDVyT1DuoXLFwnrK5wAq9S+Eqx5WA8fD7uljwBozmxt+E1gTanVhZgbcB+x2979MuM8FZjYnTLdRfsPvBp4APp/RZ6X/zwOPe/kA6lZgXbhyYznQCTxdrz7d/R53X+Luyyi/5x53999LrU8zazezmZVpyq/XyyT2urv7W8BBM6t8j/5NwCup9VnlTs4faqr0k0qfB4DVZjY9/NxX/i0n/r05ESd/6nSi5jbKV+u8DvxphO3/iPKxvyHK6buB8jG97cDecD8vjDXgr0KvLwHXV63n3wHd4fbFOvf4rynvKr4IvBButyXY528Dz4c+Xwb+S6ivCG/Qbsq7+K2hPi3Md4fHV1St609D/3uAWyfw9e/i/NVNSfUZ+vlVuO2q/Hyk9rqH9V8DPBNe+/9F+aqfFPucDvwamF1VS6pP4KvAq+Fn6IeUr1Ca8PemvpZDREQypXq4SUREEqCQEBGRTAoJERHJpJAQEZFMCgkREcmkkBARkUwKCRERyfT/AZwKe6cYtT7EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting graph on no. of words vs frequency \n",
    "#On basis of graph we can decide the number of features we want to take\n",
    "features=sorted_dic\n",
    "answer1=[]\n",
    "answer2=[]\n",
    "for i in range(len(features)):\n",
    "    answer1.append(i)\n",
    "    answer2.append(features[i][1])\n",
    "plt.plot(answer1,answer2)\n",
    "plt.axis([0,8000,1,5000])\n",
    "plt.grid()\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making x_train dataset\n",
    "#No. of rows is equivalent to rows in x_train, and column is equal to length of answer1(feature list)\n",
    "x_train_dataset=np.zeros([len(x_train),len(answer1)],int)\n",
    "for i in range(len(x_train)):\n",
    "    words=x_train[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our answer1(feature list)\n",
    "        if j in answer1:\n",
    "            x_train_dataset[i][answer1.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making x_test dataset\n",
    "#No. of rows is equivalent to rows in x_test, and column is equal to length of answer1(feature list)\n",
    "x_test_dataset=np.zeros([len(x_test),len(answer1)],int)\n",
    "for i in range(len(x_test)):\n",
    "    words=x_test[i][1].lower()\n",
    "    word=re.split(r'\\W+',words)\n",
    "    #Iterating over each word\n",
    "    for j in word:\n",
    "        #We will add the frequency corresponding to that word only which is in our answer1(feature list)\n",
    "        if j in answer1:\n",
    "            x_test_dataset[i][answer1.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  3  1 ...  0  0  0]\n",
      " [16  3  2 ...  0  0  0]\n",
      " [ 7  2  0 ...  0  0  0]\n",
      " ...\n",
      " [12  5  5 ...  0  0  0]\n",
      " [ 3  3  4 ...  0  0  0]\n",
      " [10  1  0 ...  0  0  0]]\n",
      "--------------------------\n",
      "[[ 6  4  1 ...  0  0  0]\n",
      " [ 6  3  2 ...  0  0  0]\n",
      " [ 5  2  0 ...  0  0  0]\n",
      " ...\n",
      " [10  2  2 ...  0  0  0]\n",
      " [ 5  3  2 ...  0  0  0]\n",
      " [ 8  5  9 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#printing x_train and x_test dataset \n",
    "print(x_train_dataset)\n",
    "print(\"--------------------------\")\n",
    "print(x_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK-LEARN'S IMPLEMENTATION OF NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Demonstrating confusion-matrix and classification report\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_dataset,y_train)\n",
    "y_pred=clf.predict(x_test_dataset)\n",
    "print(\"Score on training data:\",clf.score(x_train_dataset,y_train))\n",
    "print(\"Score on testing data:\",clf.score(x_test_dataset,y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Implementation of Naive Baye's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dictionary for implementing Naive Baye's\n",
    "def fit(x_train_dataset,y_train):\n",
    "    count={}\n",
    "    total_word=0\n",
    "    y_train=np.array(y_train)\n",
    "    #Total no. of document is calculated\n",
    "    count[\"total_doc\"]=len(y_train)\n",
    "    classes=set(y_train)\n",
    "    for i in classes:\n",
    "        temp=0\n",
    "        #selecting x_train corresponding to class present in y_train\n",
    "        x_train_with_i=x_train_dataset[y_train==i]\n",
    "        #finding length of data with category corresponding to i \n",
    "        temp2=x_train_with_i.shape[0]\n",
    "        count[i]={}\n",
    "        #Iterating over answer1(actual feature list)\n",
    "        for feature in answer1:\n",
    "            #Calculating total word in feature\n",
    "            l=(x_train_with_i[:,answer1.index(feature)]).sum()\n",
    "            count[i][feature]=l\n",
    "            temp+=l\n",
    "        #Total word in that class\n",
    "        count[i][\"word_in_class\"]=temp\n",
    "        #Length of data with y_train belonging to specific class\n",
    "        count[i][\"length\"]=temp2\n",
    "        \n",
    "    \n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x_test,dic,classes):\n",
    "    prob=np.log(dic[classes][\"length\"])-np.log(dic[\"total_doc\"])\n",
    "    feature=list(dic[classes].keys())\n",
    "    #-2 is done becuase there will be \"length\" and \"word in class\" present in feature. \n",
    "    for j in range (len(feature)-2):\n",
    "        xj=x_test[j]\n",
    "        #If frequency is 0, we will not consider it\n",
    "        if xj==0:\n",
    "            current_prob=0\n",
    "        else:\n",
    "            #Extra addition part is Laplace correction\n",
    "            num=dic[classes][feature[j]]+1\n",
    "            den=dic[classes][\"word_in_class\"]+len(dic[classes].keys())-2\n",
    "            current_prob=np.log(num)-np.log(den)\n",
    "        prob+=current_prob\n",
    "    return prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best_class or probable answer will be returned from here\n",
    "def predict_for_single(x_test,dic):\n",
    "    first_run=True\n",
    "    classes=dic.keys()\n",
    "    for i in classes:\n",
    "        if i==\"total_doc\":\n",
    "            continue\n",
    "        prob=probability(x_test,dic,i)\n",
    "        if first_run or prob>best_prob:\n",
    "            best_prob=prob\n",
    "            first_run=False\n",
    "            best_class=i\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_(x_test,dic):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predict_for_single(x,dic))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_test,y_pred):\n",
    "        count = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_test[i]:\n",
    "                count+=1\n",
    "        return count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell will take time to execute\n",
    "dictionary=fit(x_train_dataset,y_train)\n",
    "y_pred=predict_(x_test_dataset,dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on testing_data: 0.784\n",
      "[[17  0  0  0  0  0  0  1  0  0  0  0  0  0  0  3  0  0  1  4]\n",
      " [ 0  9  9  1  0  1  0  0  0  0  0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0 18  1  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 18  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6 16  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  2  2  1  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1 22  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  1 23  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 25  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 26  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  0  0 27  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  2  0  2  0  0  0 27  2  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  3  0  1  0  1 18  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  1  1  0  0  0  0  0  6  0 11  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 24  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 26  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  2 12  3]\n",
      " [ 8  0  0  0  0  0  1  0  0  0  0  0  0  0  0  4  3  0  3 13]]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.65      0.65      0.65        26\n",
      "           comp.graphics       0.82      0.39      0.53        23\n",
      " comp.os.ms-windows.misc       0.62      0.82      0.71        22\n",
      "comp.sys.ibm.pc.hardware       0.67      0.90      0.77        20\n",
      "   comp.sys.mac.hardware       0.89      0.70      0.78        23\n",
      "          comp.windows.x       0.70      0.74      0.72        19\n",
      "            misc.forsale       0.79      1.00      0.88        23\n",
      "               rec.autos       0.88      0.88      0.88        25\n",
      "         rec.motorcycles       0.72      0.92      0.81        25\n",
      "      rec.sport.baseball       1.00      0.93      0.96        27\n",
      "        rec.sport.hockey       0.90      0.96      0.93        27\n",
      "               sci.crypt       1.00      0.93      0.96        29\n",
      "         sci.electronics       0.69      0.79      0.74        34\n",
      "                 sci.med       0.90      0.72      0.80        25\n",
      "               sci.space       1.00      0.55      0.71        20\n",
      "  soc.religion.christian       0.77      0.96      0.86        25\n",
      "      talk.politics.guns       0.72      0.96      0.83        27\n",
      "   talk.politics.mideast       0.92      0.92      0.92        25\n",
      "      talk.politics.misc       0.60      0.52      0.56        23\n",
      "      talk.religion.misc       0.65      0.41      0.50        32\n",
      "\n",
      "                accuracy                           0.78       500\n",
      "               macro avg       0.79      0.78      0.77       500\n",
      "            weighted avg       0.79      0.78      0.78       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Score on testing_data:\",score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It can be seen that Sk learns implementation and self implementation show similar results :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
